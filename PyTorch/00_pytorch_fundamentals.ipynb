{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitoryago/AI-Machine-Learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGAaYT_VWec9"
      },
      "source": [
        "# **Pytorch Fundamentals**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lJz30MX_1fwe",
        "outputId": "ef3ead42-3a4f-43d3-eeb0-f2c23c57906e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Sep 30 14:33:13 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2kYviM3Wpy-",
        "outputId": "81ec0a62-4366-4da1-ce74-2fa1565bf25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdg-QuVyYETi"
      },
      "source": [
        "## ***Tensor***\n",
        "###**Creating Tensor**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBB6qy_PXJ-t",
        "outputId": "a39a5d45-c207-4f82-e95e-9ce90625579d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxWYPWVs2_7V",
        "outputId": "862afcda-3e80-4c0a-baac-c8aa14877ed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCEEW0i33RkY",
        "outputId": "d3d6af31-377f-4aec-c2a7-aebd8d5c7032"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get tensor back as Python int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSz1Ebj-3Z7i",
        "outputId": "d0817f75-297a-4c55-b098-3a1be0190717"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector = torch.tensor([[[2,2], [3, 3]],[[7, 7], [3, 3]]])\n",
        "vector\n",
        "# vector.ndim\n",
        "# vector.dtype\n",
        "vector.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCL_pw8J54xL"
      },
      "source": [
        "### Random Tensors\n",
        "Why random tensors?\n",
        "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVCpGVCi59ev",
        "outputId": "cdad708d-1e84-4871-e221-7b83fce36f12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 5, 5, 5])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random Tensor of shape (3, 4)\n",
        "random_tensor_1 = torch.rand(10, 5, 5, 5)\n",
        "random_tensor_1\n",
        "# random_tensor_1.shape\n",
        "# random_tensor_1.ndim\n",
        "# random_tensor_1.dtype\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T81vWHEa8mYt"
      },
      "source": [
        "### Zero and ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A6Q9PU88n74",
        "outputId": "8a7491bb-81f2-4d17-f79c-f12dbffcf7ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros = torch.zeros(size=(5,5))\n",
        "zeros*random_tensor_1\n",
        "zeros.ndim\n",
        "ones = torch.ones(size=(3,4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slFjHVA09SLs"
      },
      "source": [
        "### Creating a range of tensors and tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBTaE-nv9Pj8"
      },
      "outputs": [],
      "source": [
        "# Use torch.arange()\n",
        "torch.arange(0, 10)\n",
        "big_arange = torch.arange(start=0, end=1000, step=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c62dkcxo9yi-",
        "outputId": "b1c549df-ba19-4440-ecd6-151b332ddc37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating tensors like\n",
        "big_arange.dtype\n",
        "\n",
        "## Zeros as the same shape of big_arrange it's possible to do with ones to\n",
        "ten_zeros = torch.zeros_like(input=big_arange)\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4lpl55a-clv"
      },
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "**Note**: Tensor datatypes is one of the 3 big errors you'll run into Pytorch & deep learning:\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNvxNHoJ-Psv",
        "outputId": "5517b320-890e-4120-d6bd-e66a436d9460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Float 32 tensor\n",
        "# dtype is what datatype you want your tensor\n",
        "# device: we can change between CPU and GPU (cuda)\n",
        "# requires_grad: you want pytorch to track de gradiants with this tensors operations\n",
        "\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 3.3], dtype=None, device=None, requires_grad=False)\n",
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_-zkhH8Aafd",
        "outputId": "b6ba6095-3e02-4596-d86b-261e0f9ab23c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor = float_32_tensor.type(torch.float32)\n",
        "float_16_tensor = torch.tensor([3., 6., 9.], dtype=torch.float16)\n",
        "tensor_test = float_32_tensor * float_16_tensor\n",
        "tensor_test.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1d2faV8EABO"
      },
      "source": [
        "### Manipulating Tensors (tensor operations)\n",
        "\n",
        "Tensors operations include:\n",
        "1. Addition\n",
        "2. Subtraction\n",
        "3. Multiplication (element-wise)\n",
        "4. Division\n",
        "5. Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p-DwjKrDSgM",
        "outputId": "50bf68d2-506e-44dd-b2c3-430db743bd89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor + 10: tensor([[10.3073, 10.0217, 10.7581],\n",
            "        [10.8352, 10.4482, 10.3087],\n",
            "        [10.6158, 10.9847, 10.4006]])\n",
            "Tensor by 10: tensor([[3.0735, 0.2172, 7.5812],\n",
            "        [8.3520, 4.4824, 3.0872],\n",
            "        [6.1582, 9.8474, 4.0063]])\n",
            "Tensor minus 10: tensor([[-9.6927, -9.9783, -9.2419],\n",
            "        [-9.1648, -9.5518, -9.6913],\n",
            "        [-9.3842, -9.0153, -9.5994]])\n",
            "Tensor divided by 10: tensor([[0.0307, 0.0022, 0.0758],\n",
            "        [0.0835, 0.0448, 0.0309],\n",
            "        [0.0616, 0.0985, 0.0401]])\n",
            "Try out torch.mul: tensor([[3.0735, 0.2172, 7.5812],\n",
            "        [8.3520, 4.4824, 3.0872],\n",
            "        [6.1582, 9.8474, 4.0063]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 3)\n",
        "print(f\"Tensor + 10: {tensor+10}\")\n",
        "print(f\"Tensor by 10: {tensor * 10}\")\n",
        "print(f\"Tensor minus 10: {tensor - 10}\")\n",
        "print(f\"Tensor divided by 10: {tensor/10}\")\n",
        "print(f\"Try out torch.mul: {torch.mul(tensor, 10)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khk8G-VxFa0g"
      },
      "source": [
        "### Matrix multiplication\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzSIj4j0Fabv",
        "outputId": "4886451f-ac8b-4fa4-cce0-49b3d8447387"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[9.4462e-02, 4.7187e-04, 5.7474e-01],\n",
              "        [6.9756e-01, 2.0092e-01, 9.5305e-02],\n",
              "        [3.7923e-01, 9.6972e-01, 1.6050e-01]])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Element wise multiplication\n",
        "tensor * tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPeaqN1NGYH-",
        "outputId": "b9d06abd-16a1-4a97-8a63-d49c4701685b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.1713, 1.1711, 0.8305])\n",
            "CPU times: user 2.81 ms, sys: 977 µs, total: 3.79 ms\n",
            "Wall time: 3.67 ms\n"
          ]
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6sSq_oPHqqx",
        "outputId": "b3a30ed5-1f62-448f-a6db-208ef2f0d48f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 627 µs, sys: 983 µs, total: 1.61 ms\n",
            "Wall time: 15 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0.5795, 0.7630, 0.5434],\n",
              "        [0.8212, 0.5231, 0.8952],\n",
              "        [1.2584, 0.8493, 0.9314]])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdXi94-8KpGx"
      },
      "source": [
        "## ***Finding the min, max, mean, sum, etc (tensor aggregation)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrYR8XfcKoMM",
        "outputId": "e3615ecc-ab51-4a96-b09c-37aea5268aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor min: 0, 0\n",
            "Tensor max: 90, 90\n",
            "Tensor mean: 45.0, 45.0\n",
            "Tensor sum: 450, 450\n",
            "Finding the position of the min value 0\n",
            "Finding the position of the max value 9\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "print(f\"Tensor min: {torch.min(x)}, {x.min()}\")\n",
        "print(f\"Tensor max: {torch.max(x)}, {x.max()}\")\n",
        "\n",
        "# Find the mean - note: the torch.mean() function requires a tensor of float32 datatype to work\n",
        "print(f\"Tensor mean: {torch.mean(x.type(torch.float32))}, {x.type(torch.float32).mean()}\")\n",
        "print(f\"Tensor sum: {torch.sum(x)}, {x.sum()}\")\n",
        "\n",
        "#Finding the positional min and max\n",
        "print(f\"Finding the position of the min value {x.argmin()}\")\n",
        "print(f\"Finding the position of the max value {x.argmax()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrePMxujNMx_"
      },
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezxing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - Return a view an input tensor of certain shape but keep the same memory\n",
        "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
        "* Squeeze - removes all `1` dimensions from a tensor\n",
        "* Unsqueeze - add a `1` dimension to a target tensor\n",
        "* Permute - Return a view of the input with dimensions permuted (swapped) in certain way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "matKZS7qN67p",
        "outputId": "32c27514-021f-4ea7-ab0a-ed735fa43d4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1.],\n",
              "          [2.],\n",
              "          [3.]],\n",
              " \n",
              "         [[4.],\n",
              "          [5.],\n",
              "          [6.]],\n",
              " \n",
              "         [[7.],\n",
              "          [8.],\n",
              "          [9.]]]),\n",
              " torch.Size([3, 3, 1]))"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Let's create a tensor\n",
        "x = torch.arange(1., 10.)\n",
        "\n",
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(3, 3, 1)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkNvVPfuO2w0",
        "outputId": "f87970a2-8c53-42b0-9639-fa682ac53c55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3.],\n",
              "         [5., 5., 6.],\n",
              "         [5., 8., 9.]]),\n",
              " tensor([5., 2., 3., 5., 5., 6., 5., 8., 9.]))"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the view (a view of a tensor, shares the same memory as the original input)\n",
        "z = x.view(3,3)\n",
        "z, z.shape, x, x.shape\n",
        "\n",
        "z[:, 0] = 5\n",
        "z, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv1AUEYyPU-Q",
        "outputId": "dacba461-e8df-4a49-e3f4-79892409c15e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [8., 8., 8., 8.],\n",
              "        [9., 9., 9., 9.]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=-1)\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSHX9w3tP45m",
        "outputId": "c42a3437-41cf-433b-f3bf-d691a3faf77d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_reshaped: tensor([[[5.],\n",
            "         [2.],\n",
            "         [3.]],\n",
            "\n",
            "        [[5.],\n",
            "         [5.],\n",
            "         [6.]],\n",
            "\n",
            "        [[5.],\n",
            "         [8.],\n",
            "         [9.]]])\n",
            "\n",
            "x_reshaped shape: torch.Size([3, 3, 1])\n",
            "\n",
            "Squeezed: tensor([[5., 2., 3.],\n",
            "        [5., 5., 6.],\n",
            "        [5., 8., 9.]])\n",
            "\n",
            "Squeezed shape: torch.Size([3, 3])\n",
            "\n",
            "Unsqueezed: tensor([[[5., 2., 3.],\n",
            "         [5., 5., 6.],\n",
            "         [5., 8., 9.]]])\n",
            "\n",
            "Unsqueezed shape: torch.Size([1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "# torch.squeeze() - removes all single dimension from a target tensor\n",
        "print(f\"x_reshaped: {x_reshaped}\")\n",
        "print(f\"\\nx_reshaped shape: {x_reshaped.shape}\")\n",
        "print(f\"\\nSqueezed: {x_reshaped.squeeze()}\")\n",
        "print(f\"\\nSqueezed shape: {x_reshaped.squeeze().shape}\")\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "\n",
        "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dimension\n",
        "print(f\"\\nUnsqueezed: {x_squeezed.unsqueeze(dim=0)}\")\n",
        "print(f\"\\nUnsqueezed shape: {x_squeezed.unsqueeze(dim=0).shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbzfEVAYRsGP",
        "outputId": "6773ffa1-d57e-4812-cfaf-b7c7c3ecd0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
        "x_original = torch.rand(size=(224,224,3)) # [height, width, colour_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis (or dim) order\n",
        "x_permuted = x_original.permute(2, 0, 1) #shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\") #[colour_channels, height, width]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atSV_14YS39o"
      },
      "source": [
        "## Indexing (selecting data from tesnors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36nPyqoPS99S",
        "outputId": "c7142b58-e81e-4412-c4d1-7724f7e1fd2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x[0]: tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "x[0][0]: tensor([1, 2, 3])\n",
            "x[0][0][0]: 1\n",
            "x[:,0]: tensor([[1, 2, 3]])\n",
            "x[:, :, 0]: tensor([[1, 4, 7]])\n",
            "x[0, 0, :]: tensor([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "\n",
        "# Let's index on our new tensor\n",
        "print(f\"x[0]: {x[0]}\")\n",
        "print(f\"x[0][0]: {x[0][0]}\")\n",
        "print(f\"x[0][0][0]: {x[0][0][0]}\")\n",
        "\n",
        "# You can also use \":\" to select \"all\" of a target dimension\n",
        "print(f\"x[:,0]: {x[:, 0]}\")\n",
        "print(f\"x[:, :, 0]: {x[:, :, 0]}\")\n",
        "\n",
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "print(f\"x[0, 0, :]: {x[0, 0, :]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jf2S3qVUqfa"
      },
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "Numpy is a popular scientific Python numerical computing library. And because of this, PyTorch has functionality to interact with it.\n",
        "\n",
        "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
        "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R5xpFBJUpiH",
        "outputId": "f9b9522b-02a7-4282-f1e5-84fbc139d541"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejMOjwr_Vre3",
        "outputId": "df23272a-8909-4283-9e78-7c1524ee7564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the value of array, what will this do to tensor?\n",
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sirShrJMV3jI",
        "outputId": "0af40d95-305b-45b2-de58-61002d9b6d62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNu9AqUuWMBm"
      },
      "source": [
        "## Reproducibility (trying to take random out of random)\n",
        "\n",
        "In short how a neural network learns:\n",
        "\n",
        "`Start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> ...`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL05iX-MWK-D",
        "outputId": "0eb53e3c-9fa5-42c6-8eed-0269bd18e7d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5538, 0.2241, 0.4979],\n",
              "        [0.3291, 0.9380, 0.6343],\n",
              "        [0.4451, 0.4094, 0.3616]])"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpnUveBuW41R",
        "outputId": "7355e96a-4a1f-4c31-8c13-3c61ffd83c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1143, 0.5281, 0.5096, 0.4461],\n",
            "        [0.3470, 0.3147, 0.3414, 0.8654],\n",
            "        [0.5257, 0.1183, 0.4138, 0.7812]])\n",
            "tensor([[0.9620, 0.7205, 0.8071, 0.3182],\n",
            "        [0.5426, 0.1533, 0.2480, 0.3761],\n",
            "        [0.7314, 0.0356, 0.3718, 0.0578]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3,4)\n",
        "random_tensor_B = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ86Xf_mXhRh",
        "outputId": "40e07b52-7d64-41a5-bff7-9c04246a3709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0819, 0.4911, 0.4033, 0.3859],\n",
            "        [0.8813, 0.8811, 0.7242, 0.5033],\n",
            "        [0.8249, 0.2634, 0.3112, 0.5948]])\n",
            "tensor([[0.0819, 0.4911, 0.4033, 0.3859],\n",
            "        [0.8813, 0.8811, 0.7242, 0.5033],\n",
            "        [0.8249, 0.2634, 0.3112, 0.5948]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "# Let's make some random but reproducible tensors\n",
        "# The manual seed method only works to 1 line after you call it\n",
        "RANDOM_SEED = 777\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKp4x9W7Yhfx"
      },
      "source": [
        "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
        "\n",
        "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IohS9phQYtSC",
        "outputId": "c1e99b56-9c3c-4c76-92dc-b51917b234ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Sep 30 19:26:16 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIc3-eQjZhkk"
      },
      "source": [
        "### Check for GPU access with PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEeTueaYZgF0",
        "outputId": "4e7ce6de-cb58-4ab4-9fa5-6ba1a4bb5ba4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for GPU access with PyTorch\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SIxRkGCNZy42",
        "outputId": "7cc959cf-bb88-46db-e0fa-ff9fc1af51de"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNloNmqFaAW_",
        "outputId": "1a43af1a-9053-4663-f48f-ec549d3d2f77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoF1IyEPpGCH"
      },
      "source": [
        "## Putting tensors (and models) on the GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pgLX9ySpXKI",
        "outputId": "5d047948-5658-42be-950a-366ac978c873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor (default on the CPU)\n",
        "tensor = torch.tensor([1, 2, 3], device=\"cpu\")\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgxmPpfkpgJG",
        "outputId": "74b2f9c2-8df1-4f04-8c42-8eb073d6b3f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofxal3oppxLP",
        "outputId": "309ecfc4-0181-4d9d-9989-909cc1f63079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ],
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy\n",
        "# Move tensor back to CPU\n",
        "\n",
        "tensor_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "print(tensor_on_cpu)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNq1SA57Ud7TOtM4GLN1s4v",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
